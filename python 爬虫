import requests  ##导入requests
from bs4 import BeautifulSoup  ##导入bs4中的BeautifulSoup
import os


urls = ['https://etherscan.io/contractsVerified/{}'.format(i) for i in range(1,728,1)]
data=[]
for url in urls:
    content = requests.get(url)
    html =requests.get(url)
    soup = BeautifulSoup(html.text)
    addresss =soup.select('td > a[class="address-tag"]')
    contractnames =soup.select('tbody > tr')


    for contractname in contractnames:
        data2 = contractname.get_text("|")
        if len(data2)>50:
            data.append(data2)

filename = 'write_data_2.txt'
with open(filename,'w') as f: # 如果filename不存在会自动创建， 'w'表示写数据，写之前会清空文件中的原有数据！
    for a in data:
        f.write(a+"\n")
